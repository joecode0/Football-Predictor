{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"initial_dataset_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def get_train_test_split(data):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(data, data[\"target\"]):\n",
    "        data_train = data.loc[train_index]\n",
    "        data_test = data.loc[test_index]\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = get_train_test_split(df)\n",
    "\n",
    "X_train = train.drop('target',axis=1)\n",
    "y_train = train['target']\n",
    "X_test = test.drop('target',axis=1)\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "X_train_norm = tf.keras.utils.normalize(X_train.values,axis=1)\n",
    "X_test_norm = tf.keras.utils.normalize(X_test.values,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/joe/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_norm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_reg.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def print_complete_evaluation_statistics(original, predictions):\n",
    "    \n",
    "    accuracy = accuracy_score(original, predictions)\n",
    "    conf_matrix = confusion_matrix(original, predictions)\n",
    "#     precision = precision_score(original, predictions)\n",
    "#     recall = recall_score(original, predictions)\n",
    "#     f1 = f1_score(original, predictions)\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    \n",
    "    print(\"Accuracy: {}\\nPrecision: {}\\nRecall: {}\\nF1: {}\".format(accuracy,precision,recall,f1))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"{}\".format(conf_matrix))\n",
    "    print(\"Format:\")\n",
    "    print(\"True Negatives --- False Positives\")\n",
    "    print(\"False Negatives --- True Positives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4768015794669299\n",
      "Precision: 0\n",
      "Recall: 0\n",
      "F1: 0\n",
      "Confusion Matrix:\n",
      "[[214 161 184]\n",
      " [  0   1   0]\n",
      " [341 374 751]]\n",
      "Format:\n",
      "True Negatives --- False Positives\n",
      "False Negatives --- True Positives\n"
     ]
    }
   ],
   "source": [
    "print_complete_evaluation_statistics(predictions,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions,target):\n",
    "    count_correct = 0\n",
    "    total = len(predictions)\n",
    "    for i in range(len(predictions)):\n",
    "        p = predictions[i]\n",
    "        t = target[i]\n",
    "        if p == t: \n",
    "            count_correct += 1\n",
    "    accuracy = round(count_correct/total,7)*100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100\n",
      "Learning Rate: 0.1\n",
      "Total Epochs: 100\n",
      "Accuracy after epoch 0 = 27.246910000000003%\n",
      "Accuracy after epoch 10 = 47.37037%\n",
      "Accuracy after epoch 20 = 48.41975%\n",
      "Accuracy after epoch 30 = 48.37037%\n",
      "Accuracy after epoch 40 = 48.50617%\n",
      "Accuracy after epoch 50 = 48.790119999999995%\n",
      "Accuracy after epoch 60 = 48.85185%\n",
      "Accuracy after epoch 70 = 48.87654%\n",
      "Accuracy after epoch 80 = 48.814809999999994%\n",
      "Accuracy after epoch 90 = 48.92593%\n",
      "Test Set: Accuracy after epoch 99 = 47.13722%\n",
      "Time taken = 1.24629 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 5], name=\"x\")\n",
    "target = tf.placeholder(tf.int32, [None], name=\"target\")\n",
    "learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "\n",
    "hidden_layer_size = 100\n",
    "lr = 0.1\n",
    "epochs = 100\n",
    "\n",
    "hidden = tf.layers.dense(x, hidden_layer_size, activation=tf.tanh)\n",
    "output = tf.layers.dense(hidden, 4, activation=None) # changed to 3 because of 3 possible classes\n",
    "\n",
    "probabilities = tf.nn.softmax(output)\n",
    "predictions = tf.argmax(probabilities, axis=1)\n",
    "loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=target)\n",
    "loss = tf.reduce_mean(loss_)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "data_x = X_train\n",
    "data_targets = y_train.tolist()\n",
    "test_x = X_test\n",
    "test_y = y_test.tolist()\n",
    "print(\"Hidden Layer Size: {}\".format(hidden_layer_size))\n",
    "print(\"Learning Rate: {}\".format(lr))\n",
    "print(\"Total Epochs: {}\".format(epochs))\n",
    "start_time = time.time()\n",
    "tf.set_random_seed(20)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        result, _ = sess.run([predictions, train_op], feed_dict={x: data_x, target: data_targets, learning_rate: lr})\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Accuracy after epoch {} = {}%\".format(epoch,get_accuracy(result,data_targets)))\n",
    "    result, _ = sess.run([predictions, train_op], feed_dict={x: test_x, target: test_y, learning_rate: lr})\n",
    "    print(\"Test Set: Accuracy after epoch {} = {}%\".format(epoch,get_accuracy(result,test_y)))\n",
    "            \n",
    "end_time = time.time()\n",
    "print(\"Time taken = {} seconds\".format(round(end_time-start_time,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 5\n",
      "Learning Rate: 0.1\n",
      "Total Epochs: 200\n",
      "Accuracy after epoch 0 = 25.333329999999997%\n",
      "Accuracy after epoch 10 = 41.69136%\n",
      "Accuracy after epoch 20 = 44.97531%\n",
      "Accuracy after epoch 30 = 45.81481%\n",
      "Accuracy after epoch 40 = 46.38272%\n",
      "Accuracy after epoch 50 = 47.061730000000004%\n",
      "Accuracy after epoch 60 = 47.32099%\n",
      "Accuracy after epoch 70 = 47.58025%\n",
      "Accuracy after epoch 80 = 47.87654%\n",
      "Accuracy after epoch 90 = 47.92593%\n",
      "Accuracy after epoch 100 = 47.91358%\n",
      "Accuracy after epoch 110 = 47.864200000000004%\n",
      "Accuracy after epoch 120 = 47.93827%\n",
      "Accuracy after epoch 130 = 47.95062%\n",
      "Accuracy after epoch 140 = 48.01235%\n",
      "Accuracy after epoch 150 = 48.14815%\n",
      "Accuracy after epoch 160 = 48.18519%\n",
      "Accuracy after epoch 170 = 48.2716%\n",
      "Accuracy after epoch 180 = 48.24691%\n",
      "Accuracy after epoch 190 = 48.28395%\n",
      "Test Set: Accuracy after epoch 199 = 48.173739999999995%\n",
      "Time taken = 1.18051 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 5], name=\"x\")\n",
    "target = tf.placeholder(tf.int32, [None], name=\"target\")\n",
    "learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "\n",
    "hidden_layer_size = 5\n",
    "lr = 0.1\n",
    "epochs = 200\n",
    "\n",
    "hidden = tf.layers.dense(x, hidden_layer_size, activation=tf.tanh)\n",
    "output = tf.layers.dense(hidden, 4, activation=None) # changed to 3 because of 3 possible classes\n",
    "\n",
    "probabilities = tf.nn.softmax(output)\n",
    "predictions = tf.argmax(probabilities, axis=1)\n",
    "loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=target)\n",
    "loss = tf.reduce_mean(loss_)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "data_x = X_train\n",
    "data_targets = y_train.tolist()\n",
    "test_x = X_test\n",
    "test_y = y_test.tolist()\n",
    "print(\"Hidden Layer Size: {}\".format(hidden_layer_size))\n",
    "print(\"Learning Rate: {}\".format(lr))\n",
    "print(\"Total Epochs: {}\".format(epochs))\n",
    "start_time = time.time()\n",
    "tf.set_random_seed(20)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        result, _ = sess.run([predictions, train_op], feed_dict={x: data_x, target: data_targets, learning_rate: lr})\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Accuracy after epoch {} = {}%\".format(epoch,get_accuracy(result,data_targets)))\n",
    "    result, _ = sess.run([predictions, train_op], feed_dict={x: test_x, target: test_y, learning_rate: lr})\n",
    "    print(\"Test Set: Accuracy after epoch {} = {}%\".format(epoch,get_accuracy(result,test_y)))\n",
    "end_time = time.time()\n",
    "print(\"Time taken = {} seconds\".format(round(end_time-start_time,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 18\n",
      "Learning Rate: 0.1\n",
      "Total Epochs: 100\n",
      "Accuracy after epoch 0 = 28.30864%\n",
      "Accuracy after epoch 10 = 45.32099%\n",
      "Accuracy after epoch 20 = 46.14815%\n",
      "Accuracy after epoch 30 = 47.75309%\n",
      "Accuracy after epoch 40 = 47.92593%\n",
      "Accuracy after epoch 50 = 48.12346%\n",
      "Accuracy after epoch 60 = 48.24691%\n",
      "Accuracy after epoch 70 = 48.23457%\n",
      "Accuracy after epoch 80 = 48.296299999999995%\n",
      "Accuracy after epoch 90 = 48.37037%\n",
      "Test Set: Accuracy after epoch 99 = 48.61797%\n",
      "Time taken = 0.55391 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 5], name=\"x\")\n",
    "target = tf.placeholder(tf.int32, [None], name=\"target\")\n",
    "learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "\n",
    "hidden_layer_size = 18\n",
    "lr = 0.1\n",
    "epochs = 100\n",
    "\n",
    "hidden = tf.layers.dense(x, hidden_layer_size, activation=tf.tanh)\n",
    "output = tf.layers.dense(hidden, 4, activation=None) # changed to 3 because of 2 possible classes\n",
    "\n",
    "probabilities = tf.nn.softmax(output)\n",
    "predictions = tf.argmax(probabilities, axis=1)\n",
    "loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=target)\n",
    "loss = tf.reduce_mean(loss_)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "data_x = X_train\n",
    "data_targets = y_train.tolist()\n",
    "test_x = X_test\n",
    "test_y = y_test.tolist()\n",
    "print(\"Hidden Layer Size: {}\".format(hidden_layer_size))\n",
    "print(\"Learning Rate: {}\".format(lr))\n",
    "print(\"Total Epochs: {}\".format(epochs))\n",
    "start_time = time.time()\n",
    "tf.set_random_seed(20)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        result, _ = sess.run([predictions, train_op], feed_dict={x: data_x, target: data_targets, learning_rate: lr})\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Accuracy after epoch {} = {}%\".format(epoch,get_accuracy(result,data_targets)))\n",
    "    result, _ = sess.run([predictions, train_op], feed_dict={x: test_x, target: test_y, learning_rate: lr})\n",
    "    print(\"Test Set: Accuracy after epoch {} = {}%\".format(epoch,get_accuracy(result,test_y)))\n",
    "end_time = time.time()\n",
    "print(\"Time taken = {} seconds\".format(round(end_time-start_time,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

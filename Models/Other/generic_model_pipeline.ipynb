{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "df = pd.read_csv(\"main_database_for_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(data):\n",
    "    \n",
    "    # Stratified Train-dev split 80:20\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(data, data[\"target\"]):\n",
    "        data_train = data.loc[train_index]\n",
    "        data_test = data.loc[test_index]\n",
    "    \n",
    "    X_train = data_train.drop('target',axis=1)\n",
    "    y_train = data_train['target']\n",
    "    X_test = data_test.drop('target',axis=1)\n",
    "    y_test = data_test['target']\n",
    "    \n",
    "    # Normalise data\n",
    "    \n",
    "    X_train_norm = tf.keras.utils.normalize(X_train.values,axis=1)\n",
    "    X_test_norm = tf.keras.utils.normalize(X_test.values,axis=1)\n",
    "    \n",
    "    return X_train_norm, y_train, X_test_norm, y_test\n",
    "\n",
    "def build_model(layer_tuple_list, opt, loss, metrics):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for (val,act) in layer_tuple_list:\n",
    "        if val == \"dropout\":\n",
    "            model.add(tf.keras.layers.Dropout(act))\n",
    "        else:\n",
    "            model.add(tf.keras.layers.Dense(val, activation = act))\n",
    "        \n",
    "    model.compile(optimizer=opt,\n",
    "                 loss=loss,\n",
    "                 metrics=metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def calculate_class_weights(y_train):\n",
    "    counts = {}\n",
    "    max_count_class = 0\n",
    "    max_count = 0\n",
    "    all_classes = set(y_train.unique())\n",
    "    for c in all_classes:\n",
    "        count = len([x for x in y_train.tolist() if x == c])\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_count_class = c\n",
    "        counts[c] = count\n",
    "    class_weights = {} \n",
    "    for c in all_classes:\n",
    "        class_weights[c] = max_count/counts.get(c)\n",
    "    return class_weights\n",
    "\n",
    "def fit_model(model, X_train, y_train, X_test, y_test, epochs, use_class_weights):\n",
    "    if use_class_weights:\n",
    "        class_weight = calculate_class_weights(y_train)\n",
    "        model.fit(X_train, y_train.values,epochs = epochs, validation_data = (X_test,y_test), \n",
    "                  class_weight = class_weight)\n",
    "    else:\n",
    "        model.fit(X_train, y_train.values, epochs = epochs, validation_data = (X_test,y_test))\n",
    "    return model\n",
    "    \n",
    "def generic_build_fit(df, layer_tuple_list, epochs = 2, opt = 'adam', loss = 'sparse_categorical_crossentropy', \n",
    "                      metrics = ['accuracy'], use_class_weights = False):\n",
    "    \n",
    "    print(\"Preparing Data...\")\n",
    "    X_train, y_train, X_test, y_test = prep_data(df)\n",
    "    \n",
    "    print(\"Building Model...\")\n",
    "    model = build_model(layer_tuple_list, opt, loss, metrics)\n",
    "    \n",
    "    print(\"Fitting Model...\")\n",
    "    model = fit_model(model, X_train, y_train, X_test, y_test, epochs, use_class_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# layers = [(64,tf.nn.relu),(64,tf.nn.relu),(\"dropout\",0.5),(3,tf.nn.softmax)]\n",
    "# model = generic_build_fit(df, layers, epochs=50, use_class_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

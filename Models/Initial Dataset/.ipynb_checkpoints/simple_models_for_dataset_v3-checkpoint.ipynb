{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"initial_dataset_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "def get_train_test_split(data):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "    for train_index, test_index in split.split(data, data[\"target\"]):\n",
    "        data_train = data.loc[train_index]\n",
    "        data_test = data.loc[test_index]\n",
    "    return data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = get_train_test_split(df)\n",
    "\n",
    "X_train = train.drop('target',axis=1)\n",
    "y_train = train['target']\n",
    "X_test = test.drop('target',axis=1)\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def print_complete_evaluation_statistics(original, predictions):\n",
    "    \n",
    "    accuracy = accuracy_score(original, predictions)\n",
    "    conf_matrix = confusion_matrix(original, predictions)\n",
    "    precision = precision_score(original, predictions)\n",
    "    recall = recall_score(original, predictions)\n",
    "    f1 = f1_score(original, predictions)\n",
    "    \n",
    "    print(\"Accuracy: {}\\nPrecision: {}\\nRecall: {}\\nF1: {}\".format(accuracy,precision,recall,f1))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(\"{}\".format(conf_matrix))\n",
    "    print(\"Format:\")\n",
    "    print(\"True Negatives --- False Positives\")\n",
    "    print(\"False Negatives --- True Positives\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6243830207305034\n",
      "Precision: 0.5219251336898396\n",
      "Recall: 0.6084788029925187\n",
      "F1: 0.5618883131836501\n",
      "Confusion Matrix:\n",
      "[[777 447]\n",
      " [314 488]]\n",
      "Format:\n",
      "True Negatives --- False Positives\n",
      "False Negatives --- True Positives\n"
     ]
    }
   ],
   "source": [
    "print_complete_evaluation_statistics(predictions,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predictions,target):\n",
    "    count_correct = 0\n",
    "    total = len(predictions)\n",
    "    for i in range(len(predictions)):\n",
    "        p = predictions[i]\n",
    "        t = target[i]\n",
    "        if p == t: \n",
    "            count_correct += 1\n",
    "    accuracy = round(count_correct/total,7)*100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100\n",
      "Learning Rate: 0.5\n",
      "Total Epochs: 500\n",
      "Accuracy after epoch 0 = 39.888889999999996%\n",
      "Accuracy after epoch 10 = 39.55556%\n",
      "Accuracy after epoch 20 = 60.456790000000005%\n",
      "Accuracy after epoch 30 = 60.48148%\n",
      "Accuracy after epoch 40 = 60.456790000000005%\n",
      "Accuracy after epoch 50 = 60.518519999999995%\n",
      "Accuracy after epoch 60 = 39.80247%\n",
      "Accuracy after epoch 70 = 41.25926%\n",
      "Accuracy after epoch 80 = 40.20988%\n",
      "Accuracy after epoch 90 = 41.17284%\n",
      "Accuracy after epoch 100 = 40.259260000000005%\n",
      "Accuracy after epoch 110 = 60.518519999999995%\n",
      "Accuracy after epoch 120 = 60.456790000000005%\n",
      "Accuracy after epoch 130 = 60.456790000000005%\n",
      "Accuracy after epoch 140 = 60.456790000000005%\n",
      "Accuracy after epoch 150 = 60.456790000000005%\n",
      "Accuracy after epoch 160 = 60.456790000000005%\n",
      "Accuracy after epoch 170 = 60.469139999999996%\n",
      "Accuracy after epoch 180 = 60.469139999999996%\n",
      "Accuracy after epoch 190 = 60.456790000000005%\n",
      "Accuracy after epoch 200 = 60.456790000000005%\n",
      "Accuracy after epoch 210 = 60.469139999999996%\n",
      "Accuracy after epoch 220 = 60.34568%\n",
      "Accuracy after epoch 230 = 60.34568%\n",
      "Accuracy after epoch 240 = 60.28395%\n",
      "Accuracy after epoch 250 = 60.79012%\n",
      "Accuracy after epoch 260 = 60.2963%\n",
      "Accuracy after epoch 270 = 60.75309%\n",
      "Accuracy after epoch 280 = 60.80247%\n",
      "Accuracy after epoch 290 = 60.814809999999994%\n",
      "Accuracy after epoch 300 = 60.59259%\n",
      "Accuracy after epoch 310 = 60.77778000000001%\n",
      "Accuracy after epoch 320 = 60.814809999999994%\n",
      "Accuracy after epoch 330 = 60.814809999999994%\n",
      "Accuracy after epoch 340 = 60.864200000000004%\n",
      "Accuracy after epoch 350 = 60.888889999999996%\n",
      "Accuracy after epoch 360 = 60.888889999999996%\n",
      "Accuracy after epoch 370 = 60.90123%\n",
      "Accuracy after epoch 380 = 60.90123%\n",
      "Accuracy after epoch 390 = 60.90123%\n",
      "Accuracy after epoch 400 = 61.012350000000005%\n",
      "Accuracy after epoch 410 = 60.79012%\n",
      "Accuracy after epoch 420 = 60.77778000000001%\n",
      "Accuracy after epoch 430 = 60.77778000000001%\n",
      "Accuracy after epoch 440 = 60.79012%\n",
      "Accuracy after epoch 450 = 60.79012%\n",
      "Accuracy after epoch 460 = 60.80247%\n",
      "Accuracy after epoch 470 = 60.80247%\n",
      "Accuracy after epoch 480 = 60.80247%\n",
      "Accuracy after epoch 490 = 60.80247%\n",
      "Time taken = 7.74461 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 5], name=\"x\")\n",
    "target = tf.placeholder(tf.int32, [None], name=\"target\")\n",
    "learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "\n",
    "hidden_layer_size = 100\n",
    "lr = 0.5\n",
    "epochs = 500\n",
    "\n",
    "hidden = tf.layers.dense(x, hidden_layer_size, activation=tf.tanh)\n",
    "output = tf.layers.dense(hidden, 2, activation=None) # changed to 2 because of 2 possible classes\n",
    "\n",
    "probabilities = tf.nn.softmax(output)\n",
    "predictions = tf.argmax(probabilities, axis=1)\n",
    "loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=target)\n",
    "loss = tf.reduce_mean(loss_)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "data_x = X_train\n",
    "data_targets = y_train.tolist()\n",
    "print(\"Hidden Layer Size: {}\".format(hidden_layer_size))\n",
    "print(\"Learning Rate: {}\".format(lr))\n",
    "print(\"Total Epochs: {}\".format(epochs))\n",
    "start_time = time.time()\n",
    "tf.set_random_seed(20)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        result, _ = sess.run([predictions, train_op], feed_dict={x: data_x, target: data_targets, learning_rate: lr})\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Accuracy after epoch {} = {}%\".format(epoch,get_accuracy(result,data_targets)))\n",
    "end_time = time.time()\n",
    "print(\"Time taken = {} seconds\".format(round(end_time-start_time,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 100\n",
      "Learning Rate: 0.1\n",
      "Total Epochs: 100\n",
      "Accuracy after epoch 0 = 41.92593%\n",
      "Accuracy after epoch 10 = 41.07407%\n",
      "Accuracy after epoch 20 = 46.691359999999996%\n",
      "Accuracy after epoch 30 = 53.04938%\n",
      "Accuracy after epoch 40 = 56.24691000000001%\n",
      "Accuracy after epoch 50 = 57.87654%\n",
      "Accuracy after epoch 60 = 58.703700000000005%\n",
      "Accuracy after epoch 70 = 59.617279999999994%\n",
      "Accuracy after epoch 80 = 60.16049%\n",
      "Accuracy after epoch 90 = 60.58025%\n",
      "Time taken = 1.62451 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 5], name=\"x\")\n",
    "target = tf.placeholder(tf.int32, [None], name=\"target\")\n",
    "learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "\n",
    "hidden_layer_size = 100\n",
    "lr = 0.1\n",
    "epochs = 100\n",
    "\n",
    "hidden = tf.layers.dense(x, hidden_layer_size, activation=tf.tanh)\n",
    "output = tf.layers.dense(hidden, 2, activation=None) # changed to 2 because of 2 possible classes\n",
    "\n",
    "probabilities = tf.nn.softmax(output)\n",
    "predictions = tf.argmax(probabilities, axis=1)\n",
    "loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=target)\n",
    "loss = tf.reduce_mean(loss_)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "data_x = X_train\n",
    "data_targets = y_train.tolist()\n",
    "print(\"Hidden Layer Size: {}\".format(hidden_layer_size))\n",
    "print(\"Learning Rate: {}\".format(lr))\n",
    "print(\"Total Epochs: {}\".format(epochs))\n",
    "start_time = time.time()\n",
    "tf.set_random_seed(20)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        result, _ = sess.run([predictions, train_op], feed_dict={x: data_x, target: data_targets, learning_rate: lr})\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Accuracy after epoch {} = {}%\".format(epoch,get_accuracy(result,data_targets)))\n",
    "end_time = time.time()\n",
    "print(\"Time taken = {} seconds\".format(round(end_time-start_time,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer Size: 200\n",
      "Learning Rate: 0.01\n",
      "Total Epochs: 300\n",
      "Accuracy after epoch 0 = 39.60494%\n",
      "Accuracy after epoch 10 = 60.40740999999999%\n",
      "Accuracy after epoch 20 = 60.62963%\n",
      "Accuracy after epoch 30 = 60.814809999999994%\n",
      "Accuracy after epoch 40 = 60.74074%\n",
      "Accuracy after epoch 50 = 60.75309%\n",
      "Accuracy after epoch 60 = 60.765429999999995%\n",
      "Accuracy after epoch 70 = 60.72840000000001%\n",
      "Accuracy after epoch 80 = 60.74074%\n",
      "Accuracy after epoch 90 = 60.87654%\n",
      "Accuracy after epoch 100 = 60.888889999999996%\n",
      "Accuracy after epoch 110 = 60.888889999999996%\n",
      "Accuracy after epoch 120 = 60.90123%\n",
      "Accuracy after epoch 130 = 60.90123%\n",
      "Accuracy after epoch 140 = 60.91358%\n",
      "Accuracy after epoch 150 = 60.90123%\n",
      "Accuracy after epoch 160 = 60.888889999999996%\n",
      "Accuracy after epoch 170 = 60.90123%\n",
      "Accuracy after epoch 180 = 60.864200000000004%\n",
      "Accuracy after epoch 190 = 60.90123%\n",
      "Accuracy after epoch 200 = 60.925929999999994%\n",
      "Accuracy after epoch 210 = 60.925929999999994%\n",
      "Accuracy after epoch 220 = 60.925929999999994%\n",
      "Accuracy after epoch 230 = 60.925929999999994%\n",
      "Accuracy after epoch 240 = 60.925929999999994%\n",
      "Accuracy after epoch 250 = 60.87654%\n",
      "Accuracy after epoch 260 = 60.888889999999996%\n",
      "Accuracy after epoch 270 = 60.87654%\n",
      "Accuracy after epoch 280 = 60.83951%\n",
      "Accuracy after epoch 290 = 60.864200000000004%\n",
      "Time taken = 6.09371 seconds\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 5], name=\"x\")\n",
    "target = tf.placeholder(tf.int32, [None], name=\"target\")\n",
    "learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "\n",
    "hidden_layer_size = 200\n",
    "lr = 0.01\n",
    "epochs = 300\n",
    "\n",
    "hidden = tf.layers.dense(x, hidden_layer_size, activation=tf.tanh)\n",
    "output = tf.layers.dense(hidden, 2, activation=None) # changed to 2 because of 2 possible classes\n",
    "\n",
    "probabilities = tf.nn.softmax(output)\n",
    "predictions = tf.argmax(probabilities, axis=1)\n",
    "loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=target)\n",
    "loss = tf.reduce_mean(loss_)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "data_x = X_train\n",
    "data_targets = y_train.tolist()\n",
    "print(\"Hidden Layer Size: {}\".format(hidden_layer_size))\n",
    "print(\"Learning Rate: {}\".format(lr))\n",
    "print(\"Total Epochs: {}\".format(epochs))\n",
    "start_time = time.time()\n",
    "tf.set_random_seed(20)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(epochs):\n",
    "        result, _ = sess.run([predictions, train_op], feed_dict={x: data_x, target: data_targets, learning_rate: lr})\n",
    "        if epoch % 10 == 0:\n",
    "            print(\"Accuracy after epoch {} = {}%\".format(epoch,get_accuracy(result,data_targets)))\n",
    "end_time = time.time()\n",
    "print(\"Time taken = {} seconds\".format(round(end_time-start_time,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
